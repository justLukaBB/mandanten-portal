---
phase: 03-llm-prompt-optimization
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - app/services/deduplicator.py
  - app/routers/deduplication.py
autonomous: true

must_haves:
  truths:
    - "deduplicate_with_llm() sends only minimal fields (4 per creditor) to Gemini instead of full creditor objects"
    - "deduplicate_with_llm() receives index-based group arrays from Gemini instead of full merged JSON"
    - "deduplicate_with_llm() uses Vertex AI structured output (response_mime_type + response_schema) for guaranteed valid JSON"
    - "deduplicate_with_llm() validates LLM response with validate_dedup_response() before using results"
    - "deduplicate_with_llm() skips LLM call for 0-1 creditors (returns immediately)"
    - "deduplicate_with_llm() still returns List[Dict] matching existing caller expectations (backward compatible)"
    - "On validation failure, deduplicate_with_llm() falls back to returning original creditors (same as current error handling)"
    - "Both paths (pipeline process_deduplication + router /deduplicate-all) use the same updated method"
  artifacts:
    - path: "app/services/deduplicator.py"
      provides: "Updated deduplicate_with_llm with minimal payload and index-based output"
      contains: "prepare_creditors_for_llm"
    - path: "app/routers/deduplication.py"
      provides: "Updated /deduplicate-all endpoint preserving backward-compatible response schema"
      contains: "deduplicate_all"
  key_links:
    - from: "deduplicate_with_llm"
      to: "prepare_creditors_for_llm"
      via: "function call to build minimal payload"
      pattern: "prepare_creditors_for_llm\\(creditors\\)"
    - from: "deduplicate_with_llm"
      to: "build_dedup_prompt"
      via: "function call to build German prompt"
      pattern: "build_dedup_prompt\\("
    - from: "deduplicate_with_llm"
      to: "validate_dedup_response"
      via: "function call to validate LLM response"
      pattern: "validate_dedup_response\\("
    - from: "deduplicate_with_llm"
      to: "get_dedup_response_schema"
      via: "Vertex AI generation_config response_schema"
      pattern: "get_dedup_response_schema\\(\\)"
---

<objective>
Wire the new minimal-payload prompt infrastructure (from Plan 01) into the live `deduplicate_with_llm()` method, replacing the current full-JSON prompt with the optimized index-based approach. Update the method to use Vertex AI structured output and two-layer validation.

Purpose: Completes Phase 3 by making the actual LLM call use minimal input and return index-based groups, satisfying all three requirements (LLM-01, LLM-02, LLM-03). The method must remain backward compatible — callers still receive `List[Dict]`.

Output: Updated `deduplicate_with_llm()` in deduplicator.py and minor adjustment to deduplication router.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-llm-prompt-optimization/03-CONTEXT.md
@.planning/phases/03-llm-prompt-optimization/03-RESEARCH.md
@.planning/phases/03-llm-prompt-optimization/03-01-SUMMARY.md

Source files to modify (FastAPI service — DIFFERENT repo):
@/Users/luka.s/Cursor : Mandanten - Portal/Creditor-process-fastAPI/app/services/deduplicator.py
@/Users/luka.s/Cursor : Mandanten - Portal/Creditor-process-fastAPI/app/routers/deduplication.py
@/Users/luka.s/Cursor : Mandanten - Portal/Creditor-process-fastAPI/app/services/gemini_rate_limiter.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite deduplicate_with_llm() to use minimal payload and index-based output</name>
  <files>/Users/luka.s/Cursor : Mandanten - Portal/Creditor-process-fastAPI/app/services/deduplicator.py</files>
  <action>
Replace the ENTIRE body of the `deduplicate_with_llm()` method in `CreditorDeduplicator` class. Keep the same method signature: `async def deduplicate_with_llm(self, creditors: List[Dict[str, Any]]) -> List[Dict[str, Any]]`.

The new implementation:

```python
async def deduplicate_with_llm(self, creditors: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Use Gemini to identify duplicate creditor groups, then reconstruct
    the creditor list with duplicates grouped by index.

    Phase 3 optimization: sends only minimal identifying fields to LLM,
    receives index-based group arrays, and returns original creditor dicts
    grouped for downstream merging (Phase 4).

    Returns creditors with source_documents arrays. Duplicate groups have
    their source_documents combined. Until Phase 4 merging is implemented,
    the first creditor in each group is kept as the representative, with
    combined source_documents.
    """
    if not creditors:
        return []

    # Skip LLM call for single creditor
    if len(creditors) <= 1:
        result = []
        for c in creditors:
            src_docs = c.get("source_documents")
            if isinstance(src_docs, str):
                src_docs = [src_docs]
            if not src_docs:
                src_docs = [c.get("source_document") or c.get("filename") or "unknown"]
            result.append({**c, "source_documents": src_docs, "merged_from": 1})
        return result

    try:
        # Step 1: Build minimal payload (LLM-01)
        creditors_str = prepare_creditors_for_llm(creditors)
        prompt = build_dedup_prompt(creditors_str, len(creditors))

        logger.info(
            f"Sending {len(creditors)} creditors to Gemini for deduplication "
            f"(minimal payload, index-based output)"
        )

        # Step 2: Call Gemini with structured output (LLM-02, LLM-03)
        response = generate_content_with_retry_sync(
            self.model,
            [prompt],
            operation_name="deduplicate_with_llm",
            generation_config={
                "max_output_tokens": 8192,
                "response_mime_type": "application/json",
                "response_schema": get_dedup_response_schema()
            }
        )
        response_text = response.text.strip()

        # Step 3: Validate response (two-layer: schema + semantic)
        validated = validate_dedup_response(response_text, len(creditors))

        # Step 4: Reconstruct creditor list from groups
        # Until Phase 4 (code-based merge), use simple strategy:
        # - For each group, keep the first creditor as representative
        # - Combine source_documents from all creditors in the group
        # - Set merged_from to group size
        # - Preserve needs_manual_review with OR logic
        result = []
        for group in validated.groups:
            if len(group) == 1:
                # Singleton — no merge needed
                c = creditors[group[0]]
                src_docs = c.get("source_documents")
                if isinstance(src_docs, str):
                    src_docs = [src_docs]
                if not src_docs:
                    src_docs = [c.get("source_document") or c.get("filename") or "unknown"]
                result.append({
                    **c,
                    "source_documents": src_docs,
                    "merged_from": 1
                })
            else:
                # Duplicate group — simple merge (Phase 4 will improve)
                primary = dict(creditors[group[0]])  # Copy first as base

                # Combine source_documents from all group members
                all_src_docs = []
                seen_docs = set()
                any_needs_review = False
                all_review_reasons = []

                for idx in group:
                    c = creditors[idx]
                    # Collect source documents
                    src_docs = c.get("source_documents")
                    if isinstance(src_docs, str):
                        src_docs = [src_docs]
                    if not src_docs:
                        src_docs = [c.get("source_document") or c.get("filename") or "unknown"]
                    for doc in src_docs:
                        if doc not in seen_docs:
                            seen_docs.add(doc)
                            all_src_docs.append(doc)

                    # OR logic for needs_manual_review
                    if c.get("needs_manual_review"):
                        any_needs_review = True

                    # Collect review reasons
                    reasons = c.get("review_reasons", [])
                    if isinstance(reasons, list):
                        for r in reasons:
                            if r and r not in all_review_reasons:
                                all_review_reasons.append(r)

                primary["source_documents"] = all_src_docs
                primary["merged_from"] = len(group)
                primary["needs_manual_review"] = any_needs_review or primary.get("needs_manual_review", False)
                primary["review_reasons"] = all_review_reasons if all_review_reasons else primary.get("review_reasons", [])

                result.append(primary)

        logger.info(
            f"Deduplication complete: {len(creditors)} -> {len(result)} unique creditors "
            f"({len(creditors) - len(result)} duplicates removed)"
        )
        return result

    except Exception as e:
        logger.error(f"LLM deduplication failed: {e}")
        # Fallback: return original creditors unchanged (same as before)
        return [
            {
                **c,
                "source_documents": [c.get("source_document") or c.get("filename") or "unknown"],
                "merged_from": 1
            }
            for c in creditors
        ]
```

Key changes from the old implementation:
- **No more `json.dumps(creditors, indent=2)` of full objects** — uses `prepare_creditors_for_llm()` for minimal payload
- **No more prompt with full creditor JSON** — uses `build_dedup_prompt()` for compact German prompt
- **No more markdown code block stripping / regex cleanup** — Vertex AI structured output guarantees valid JSON
- **No more `json.loads` of full merged creditor JSON** — uses `validate_dedup_response()` for index arrays
- **Backward compatible return type** — still returns `List[Dict]` with same field structure
- **Preserves OR logic for needs_manual_review** — same as v1 behavior
- **Skip LLM call for <= 1 creditor** — no point calling Gemini for nothing

IMPORTANT: The `generate_content_with_retry_sync` function already supports passing `generation_config` as a dict. The Vertex AI SDK accepts `response_mime_type` and `response_schema` in the generation config dict. No changes needed to the rate limiter.

Do NOT modify the `aggregate_creditors()`, `_check_manual_review()`, `create_excel_bytes()`, `create_excel_base64()`, or `process_deduplication()` methods — they remain unchanged.
  </action>
  <verify>
Read deduplicator.py and confirm:
1. `deduplicate_with_llm()` calls `prepare_creditors_for_llm(creditors)` (not `json.dumps`)
2. `deduplicate_with_llm()` calls `build_dedup_prompt(creditors_str, len(creditors))`
3. `generation_config` includes `response_mime_type` and `response_schema`
4. `validate_dedup_response(response_text, len(creditors))` is called
5. Group reconstruction logic iterates `validated.groups`
6. OR logic for `needs_manual_review` is present
7. `source_documents` are combined across group members
8. Fallback on exception returns original creditors (same as before)
9. Skip logic for <= 1 creditor exists
10. No old code remains (no markdown stripping, no regex cleanup, no json.dumps of full objects)
11. Method signature unchanged: `async def deduplicate_with_llm(self, creditors: List[Dict[str, Any]]) -> List[Dict[str, Any]]`
12. `python -c "import ast; ast.parse(open('app/services/deduplicator.py').read())"` passes
  </verify>
  <done>
deduplicate_with_llm() sends minimal 4-field payload, receives index arrays, validates with two-layer validation, and reconstructs creditor list. Backward compatible with existing callers.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify router /deduplicate-all backward compatibility</name>
  <files>/Users/luka.s/Cursor : Mandanten - Portal/Creditor-process-fastAPI/app/routers/deduplication.py</files>
  <action>
Review `app/routers/deduplication.py` to confirm it remains compatible with the updated `deduplicate_with_llm()`.

The router calls:
```python
deduplicated = await deduplicator.deduplicate_with_llm(formatted_creditors)
```

Then iterates `deduplicated` to build `result_creditors` for the Node.js response.

Since `deduplicate_with_llm()` still returns `List[Dict]` with the same fields, the router should work without changes. However, verify and make ONE adjustment if needed:

**Check:** The router builds `node_cred` from `deduplicated` entries. The updated method now properly sets `source_documents` (array) and `merged_from` (int) on every returned creditor. The router currently does:
```python
"source_documents": cred.get("source_documents", [cred.get("source_document")]) if cred.get("source_document") else [],
```

This is safe because the updated method always sets `source_documents` as a list. No change needed here.

**Check:** The router formats output as:
```python
return {
    "deduplicated_creditors": result_creditors,
    "stats": stats
}
```

This response schema is unchanged. No modification needed.

If the router file needs NO changes, confirm this by reading it and explicitly logging "Router /deduplicate-all is backward compatible — no changes needed."

If any edge case is found (e.g., the router accesses a field that the updated method no longer returns), fix it minimally.
  </action>
  <verify>
1. Read deduplication.py router
2. Confirm it calls `deduplicate_with_llm()` with same signature
3. Confirm the response fields it accesses (sender_name, sender_address, etc.) are all still present in the returned dicts
4. Confirm the response schema to Node.js (`deduplicated_creditors` + `stats`) is unchanged
5. Run `python -c "import ast; ast.parse(open('app/routers/deduplication.py').read())"` to verify syntax
  </verify>
  <done>
Router /deduplicate-all confirmed backward compatible with updated deduplicate_with_llm(). Response schema to Node.js backend unchanged (PATH-02 partially satisfied).
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `deduplicator.py` compiles: `python -c "import ast; ast.parse(open('app/services/deduplicator.py').read())"`
2. `deduplication.py` compiles: `python -c "import ast; ast.parse(open('app/routers/deduplication.py').read())"`
3. `deduplicate_with_llm()` no longer contains `json.dumps(creditors` (the old full-payload approach)
4. `deduplicate_with_llm()` contains calls to `prepare_creditors_for_llm`, `build_dedup_prompt`, `validate_dedup_response`, `get_dedup_response_schema`
5. The method signature and return type are unchanged
6. Both callers (process_deduplication pipeline + /deduplicate-all router) continue to work with the same API
</verification>

<success_criteria>
- LLM-01 COMPLETE: `deduplicate_with_llm()` sends only sender_name, reference_number, is_representative, actual_creditor to Gemini
- LLM-02 COMPLETE: Gemini returns `{"groups": [[0,3,7], [2,5], ...]}` and the method validates + reconstructs creditor list
- LLM-03 COMPLETE: Structured output with response_schema guarantees valid JSON; minimal payload keeps token usage well under 8192 for 50 creditors
- Backward compatible: callers receive same List[Dict] response format; Node.js response schema unchanged
- Error handling preserved: validation failure or LLM error falls back to returning original creditors
</success_criteria>

<output>
After completion, create `.planning/phases/03-llm-prompt-optimization/03-02-SUMMARY.md`
</output>
